# PRD

## Product Name: **Veya**

## Version: 1.0 (MVP)

## Type: AI-driven Language Growth Desktop Tool

---

# 1. 产品愿景（Vision）

Veya 是一个 **AI 驱动的语言理解与听说强化系统级工具**，帮助学习者通过：

* 划词
* 截图
* 语境分析
* 口语化重构
* 播客生成

实现"理解 → 听懂 → 说出"的闭环。

核心目标不是翻译，而是：

> 提升语言理解深度与表达能力。

---

# 2. 目标用户（Target Users）

面向所有语言学习者：

* 职场人士
* 出国考试人群
* 技术人员
* 自主学习者

共性特征：

* 有真实阅读场景（网页 / PDF / 文档）
* 需要即时理解
* 希望提升听说能力
* 使用桌面环境频繁

---

# 3. 核心问题（Problem Statement）

当前学习工具存在问题：

1. 翻译只给结果，不解释结构
2. OCR 只识别，不推测补全
3. 语音工具只是朗读，不转化为学习脚本
4. 工具之间割裂，没有闭环

Veya 解决：

* 多模态输入统一处理
* 深度语言解释
* 自动播客化
* 长期学习强化

---

# 4. 核心功能（MVP 范围）

---

## 4.1 划词解析（Text Insight）

### 功能描述

用户在任意应用中划词（通过系统 Accessibility API 实现）：

* 自动检测语言
* 弹出悬浮窗
* 流式输出结构化分析结果

### 输出结构（流式呈现）

* 原文
* 逐词解释
* 句子结构分析
* 精准翻译
* 更口语版本
* 更简单版本

### 非目标

* 不做复杂文档管理
* 不做全文批量翻译

---

## 4.2 截图识别（Vision Capture）

### 功能描述

用户通过全局快捷键触发截图，框选屏幕区域：

* 优先调用系统原生 OCR 能力（macOS Vision Framework / Windows OCR API）
* 原生 OCR 识别后，可选通过 AI 模型对截断、模糊文本进行推断补全
* 生成结构化解释（流式输出）

### AI 补全策略

* 系统设置中提供"AI 智能补全"开关，用户可自行决定是否启用
* 启用时：原生 OCR 结果 → AI 模型推断补全 → 结构化输出
* 关闭时：仅使用原生 OCR 结果 → 结构化输出
* AI 补全的内容在界面上以视觉标记区分，让用户知道哪些是推测内容

---

## 4.3 播客生成（Cast Engine）

### 输入

* 划词结果
* 截图内容
* 用户自定义文本

### 处理流程

1. 内容理解
2. 转化为口语讲解稿
3. 分段结构化
4. 生成音频文件

### 输出选项

* 慢速模式
* 正常语速
* 双语对照
* 单语沉浸模式

输出格式：

* MP3

### 音频存储策略

* 生成的播客默认为临时缓存，软件关闭时自动删除
* 用户可主动选择"保存"，保存后的音频持久化到本地存储
* 系统设置中可配置缓存清理策略（如：保存音频的最大占用空间、自动清理超过 N 天的保存音频）

### TTS 服务配置

* 支持按语言种类配置不同的 TTS 服务地址
* 例如：英语使用 ElevenLabs，中文使用其他 TTS 服务
* 用户可在设置中为每种语言指定独立的 TTS API 地址

---

## 4.4 悬浮窗（主交互界面）

### 交互方式

悬浮窗是 Veya 的主要呈现界面：

* 划词或截图后自动弹出
* 默认用完即消（失去焦点后自动隐藏）
* 支持 Pin 功能，Pin 住后常驻屏幕
* 可直接在悬浮窗内触发播客生成
* 可在悬浮窗内保存播客、播放音频

---

## 4.5 多模型 API 配置系统

### 用户可配置：

* 文本模型 API
* 视觉模型 API（用于 AI 补全，非 OCR）
* 语音模型 API（按语言种类独立配置）

支持：

* OpenAI 兼容接口
* 自定义 Base URL
* 本地模型（支持完全离线使用）

默认兼容：

* OpenAI
* Anthropic
* ElevenLabs
* Ollama

### 离线模式

* 配置本地模型（如 Ollama）后，支持完全离线使用
* 离线模式下，划词解析、截图识别（原生 OCR + 本地 AI 补全）、播客生成均可正常工作

---

## 4.6 学习记录（Lightweight）

MVP 仅记录：

* 查询历史
* 播客历史（仅用户主动保存的）
* 常用词

暂不实现：

* 完整词汇掌握度建模
* 智能学习计划

---

## 4.7 系统设置

用户可在系统设置中配置：

* AI 智能补全开关（截图识别场景）
* TTS 服务地址（按语言种类配置）
* 缓存清理策略（最大空间 / 自动清理天数）
* 模型 API 配置
* 全局快捷键
* 界面语言（国际化）

---

# 5. 非功能需求（Non-Functional Requirements）

### 性能

* 划词响应：流式输出，首字符呈现 < 500ms（本地模型）/ < 1.5s（远程 API）
* 截图识别：原生 OCR < 1 秒，AI 补全额外 < 2 秒（依赖模型）

### 稳定性

* API 失败自动重试（可配置重试次数）
* API 错误时向用户展示具体报错信息（如：Key 无效、余额不足、网络超时、模型不可用等）

### 安全

* API Key 使用 Tauri Stronghold 加密存储
* 不上传用户数据（默认），所有数据本地存储

### 国际化（i18n）

* 默认支持中文、英文
* 架构上支持扩展其他语言
* 用户可在系统设置中切换界面语言

---

# 6. 系统架构

## 桌面框架

* Tauri 2
* Rust 后端
* React 前端

---

## 数据存储

* SQLite（查询历史、播客记录、用户设置）
* 本地文件系统（保存的音频文件、临时缓存音频）
* Tauri Stronghold（API Key 等敏感配置加密存储）

---

# 7. 用户流程（核心路径）

### 场景 1：阅读网页

划词 →
悬浮窗弹出 →
流式展示结构分析 →
在悬浮窗内点击生成播客 →
听 →
选择保存或关闭（关闭后缓存自动清理）

---

### 场景 2：看图片内容

全局快捷键截图 →
框选区域 →
原生 OCR 识别（+ 可选 AI 补全）→
悬浮窗展示解释 →
生成讲解音频

---

# 8. 未来版本方向（不属于 MVP）

* 用户词汇能力模型
* CEFR 等级分析
* 自动难度调节（i+1）
* 每日复习推荐
* Anki 导出
* 语音对话练习
* Shadowing 模式

---

# 9. 竞争差异

Veya 不等同于：

* Google Translate
* DeepL

差异点：

* 深度结构解释
* 口语重构
* 播客化能力
* 多模型可插拔
* 支持完全离线使用
* 系统级集成（划词 + 截图，无需切换应用）

---

# 10. 成功指标（MVP）

* 日活用户
* 每日生成播客次数
* 划词次数
* 用户留存率（7天）

> 注：需实现 opt-in 的匿名使用统计，用户可在设置中关闭。

---

# 11. MVP 核心原则

不做：

* 社交功能
* 在线账户体系
* 复杂学习系统

只做：

> 强大、快速、稳定的语言理解与播客生成能力，支持在线与离线双模式。
